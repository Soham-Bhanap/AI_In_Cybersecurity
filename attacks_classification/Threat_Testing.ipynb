{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075e9324-0632-438f-ac6b-548ea1dfc94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda (RTX 4060)\n",
      "Dataset loaded successfully.\n",
      "Columns in dataset: ['url', 'type']\n",
      "Extracting features from URLs...\n",
      "Epoch 1, Loss: 0.4093\n",
      "Epoch 11, Loss: 0.3084\n",
      "Epoch 21, Loss: 0.2830\n",
      "Epoch 31, Loss: 0.2296\n",
      "Epoch 41, Loss: 0.2342\n",
      "\n",
      "=== Model Evaluation ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.90      0.99      0.94     85621\n",
      "  defacement       0.92      0.96      0.94     19292\n",
      "     malware       0.94      0.86      0.90      6504\n",
      "    phishing       0.86      0.48      0.62     18822\n",
      "\n",
      "    accuracy                           0.90    130239\n",
      "   macro avg       0.91      0.82      0.85    130239\n",
      "weighted avg       0.90      0.90      0.89    130239\n",
      "\n",
      "✅ GPU-optimized model saved as 'gpu_forest_model.pth'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device} (RTX 4060)\")\n",
    "\n",
    "# =====================\n",
    "# DATA PREPROCESSING\n",
    "# =====================\n",
    "def extract_features(url):\n",
    "    \"\"\"Extract URL security features\"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    domain = parsed.netloc\n",
    "    path = parsed.path\n",
    "    \n",
    "    features = {\n",
    "        'url_length': len(url),\n",
    "        'domain_length': len(domain),\n",
    "        'num_digits': sum(c.isdigit() for c in url),\n",
    "        'special_chars': sum(url.count(c) for c in ['@', '?', '=', '.', '-', '_', '/']),\n",
    "        'has_https': 1 if parsed.scheme == 'https' else 0,\n",
    "        'num_subdomains': domain.count('.') - 1 if domain.count('.') > 1 else 0,\n",
    "        'path_length': len(path),\n",
    "        'num_params': path.count('?') + path.count('&'),\n",
    "        'has_port': 1 if ':' in domain else 0,\n",
    "        'is_ip': 1 if re.match(r'\\d+\\.\\d+\\.\\d+\\.\\d+', domain) else 0,\n",
    "        'file_extension': 1 if '.' in path.split('/')[-1] else 0,\n",
    "        'entropy': calculate_entropy(url),\n",
    "        'num_redirects': url.count('//') - 1,\n",
    "        'has_phish_keywords': 1 if any(kw in url.lower() for kw in ['login', 'verify', 'secure', 'account']) else 0\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def calculate_entropy(string):\n",
    "    \"\"\"Calculate Shannon entropy of URL string\"\"\"\n",
    "    prob = [float(string.count(c)) / len(string) for c in set(string)]\n",
    "    return -sum(p * np.log2(p) for p in prob)\n",
    "\n",
    "# =====================\n",
    "# LOAD AND PREPARE DATA\n",
    "# =====================\n",
    "# Use relative path to avoid file location issues\n",
    "try:\n",
    "    df = pd.read_csv(\"malicious_phish.csv\")\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File 'malicious_phish.csv' not found in current directory\")\n",
    "    print(\"Please ensure the file is in the same directory as this script\")\n",
    "    exit()\n",
    "\n",
    "# Check actual column names\n",
    "print(\"Columns in dataset:\", df.columns.tolist())\n",
    "\n",
    "# Adjust column names based on actual dataset\n",
    "url_column = 'url'  # Column containing URLs\n",
    "label_column = 'type'  # Column containing attack types\n",
    "\n",
    "# Feature extraction\n",
    "print(\"Extracting features from URLs...\")\n",
    "features = df[url_column].apply(extract_features).apply(pd.Series)\n",
    "X = features.values.astype(np.float32)\n",
    "y = df[label_column].values\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Save label encoder\n",
    "joblib.dump(le, 'label_encoder.pkl')\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to PyTorch tensors and move to GPU\n",
    "X_train_tensor = torch.tensor(X_train).float().to(device)\n",
    "y_train_tensor = torch.tensor(y_train).long().to(device)\n",
    "X_test_tensor = torch.tensor(X_test).float().to(device)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "\n",
    "# =====================\n",
    "# GPU-OPTIMIZED MODEL\n",
    "# =====================\n",
    "class ForestNet(nn.Module):\n",
    "    \"\"\"PyTorch implementation of Random Forest equivalent\"\"\"\n",
    "    def __init__(self, input_size, num_classes, num_trees=100, tree_depth=10):\n",
    "        super().__init__()\n",
    "        self.trees = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(input_size, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32, num_classes)\n",
    "            ) for _ in range(num_trees)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = [tree(x) for tree in self.trees]\n",
    "        return torch.stack(outputs).mean(dim=0)\n",
    "\n",
    "# Initialize model\n",
    "model = ForestNet(\n",
    "    input_size=X_train.shape[1],\n",
    "    num_classes=len(le.classes_),\n",
    "    num_trees=300,\n",
    "    tree_depth=5\n",
    ").to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(50):\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    y_pred = test_outputs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "print(\"\\n=== Model Evaluation ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'input_size': X_train.shape[1],\n",
    "    'num_classes': len(le.classes_),\n",
    "    'label_encoder': le\n",
    "}, 'gpu_forest_model.pth')\n",
    "print(\"✅ GPU-optimized model saved as 'gpu_forest_model.pth'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf470c-25db-4a9e-b5eb-20dd58a99cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e7ec5-2246-4ac2-b991-c4701d34f2de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
